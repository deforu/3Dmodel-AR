<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AR.js Local Validation</title>
  <script src="vendor/vendoraframe.min.js"></script>
  <script src="vendor/vendoraframe-ar.js"></script>
  <style>
    body {
      margin: 0;
      overflow: hidden;
    }
    #loader {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background-color: rgba(0, 0, 0, 0.8);
      color: white;
      display: flex;
      justify-content: center;
      align-items: center;
      font-family: sans-serif;
      font-size: 2em;
      z-index: 1000;
    }
    #capture-btn {
      position: fixed;
      bottom: 20px;
      right: 20px;
      padding: 10px 15px;
      font-size: 1.2em;
      background-color: #007bff;
      color: white;
      border: none;
      border-radius: 5px;
      cursor: pointer;
      z-index: 1000;
    }
    #toast {
      position: fixed;
      bottom: 20px;
      left: 50%;
      transform: translateX(-50%);
      background-color: #f44336;
      color: white;
      padding: 16px;
      border-radius: 4px;
      z-index: 1001;
      visibility: hidden;
      opacity: 0;
      transition: visibility 0s, opacity 0.5s linear;
    }
    #toast.show {
      visibility: visible;
      opacity: 1;
    }
    
  </style>
</head>
<body>
  

  <div id="loader">読み込み中…</div>
  <div id="toast">カメラの初期化に失敗しました。</div>
  <button id="capture-btn">📷 撮影</button>

  <!-- AR.jsの設定: ウェブカメラをソースとして使用し、特定の解像度とカメラパラメータを指定します。 -->
  <a-scene
    embedded
    arjs="
      sourceType: webcam;
      sourceWidth: 640;
      sourceHeight: 480;
      displayWidth: 640;
      displayHeight: 480;
      debugUIEnabled: false;
      cameraParametersUrl: vendor/camera_para.dat;
    "
    vr-mode-ui="enabled: false"
    renderer="antialias: true; alpha: true; preserveDrawingBuffer: true"
    id="scene"
  >
  <!-- 3Dモデルのアセット: ここで3Dモデルをプリロードします。 -->
    <a-assets>
        <a-asset-item id="user-model" src="assets/Merge_01_tex.gltf"></a-asset-item>
    </a-assets>

    <a-marker type="pattern" url="vendor/hiro.patt" id="marker">
      <!-- デバッグ用平面: マーカーの向きや位置を確認するための半透明の緑色の平面です。-->
      <a-plane
        position="0 0 0"
        rotation="-90 0 0"
        width="1"
        height="1"
        material="opacity: 0.5; color: #00ff00;"
      ></a-plane>

      <!-- デバッグ用ボックス: モデルが読み込まれる前に一時的に表示される緑色のボックスです。-->
      <a-box
        id="debug-box"
        position="0 0.25 0"
        scale="0.2 0.2 0.2"
        material="color: green;"
        visible="true"
      ></a-box>

      <!-- 3Dモデル: ここに表示したい3Dモデルを配置します。gltf-model属性でa-assetsで定義したモデルを参照します。-->
      <a-entity
        id="model"
        rotation="-90 0 0"
        gltf-model="#user-model"

        auto-place="targetSize: 2.0; layFlat: false" 
        visible="false"
      ></a-entity>
    </a-marker>
    <!-- カメラエンティティ: AR.jsがマーカーを追跡するために必要です。 -->
    <a-entity camera></a-entity>
  </a-scene>

  <script>
    // auto-place コンポーネント: 3Dモデルをマーカー上に自動で配置、スケール、位置調整するためのカスタムコンポーネントです。
    AFRAME.registerComponent('auto-place', {
      schema: {
        targetSize: { type: 'number', default: 0.3 },
        layFlat: { type: 'boolean', default: false }
      },
      init: function () {
        this.el.addEventListener('model-loaded', (e) => {
          console.log('[model] loaded');
          const model = e.detail.model;
          if (!model) {
            console.error('[auto-place] model not found in event detail.');
            return;
          }

          // モデルがシーングラフに完全に統合されるまで少し待機します。これにより、正確なバウンディングボックス計算が可能になります。
          setTimeout(() => {
            const el = this.el;

            // バウンディングボックスの計算: モデルのサイズと中心を把握します。
            const box = new THREE.Box3().setFromObject(model);
            const size = box.getSize(new THREE.Vector3());
            const center = box.getCenter(new THREE.Vector3());

            // 1. モデルのジオメトリ自体を中央に配置します。これにより、メッシュがエンティティの原点に対して移動します。
            model.position.x -= center.x;
            model.position.y -= center.y;
            model.position.z -= center.z;

            // 2. エンティティを目標サイズに合わせてスケールします。
            const maxDim = Math.max(size.x, size.y, size.z);
            if (maxDim > 0) {
              const scale = this.data.targetSize / maxDim;
              el.setAttribute('scale', `${scale} ${scale} ${scale}`);
            }

            // 3. エンティティを配置します。スケール後、モデルの「底」がy=0になるように調整します。
            const scaledY = (size.y / 2) * (el.object3D.scale.y);
            el.object3D.position.y = scaledY;

            // 4. オプション: モデルを平坦化（X軸に-90度回転）します。
            if (this.data.layFlat) {
              el.setAttribute('rotation', '-90 0 0');
            }

            // 5. モデルを可視化します。デバッグ用の緑色のボックスは非表示にします。
            document.querySelector('#debug-box').setAttribute('visible', 'false');
            el.setAttribute('visible', 'true');
            console.log('[model] auto-placed and made visible.');
          }, 0);
        });
      }
    });


    document.addEventListener('DOMContentLoaded', () => {
      const sceneEl = document.querySelector('a-scene');
      const loaderEl = document.querySelector('#loader');
      const markerEl = document.querySelector('#marker');
      const modelEl = document.querySelector('#model'); // Get model element
      const captureBtn = document.querySelector('#capture-btn');
      const toastEl = document.querySelector('#toast');

      let captureWidth = 640;  // デフォルトの解像度
      let captureHeight = 480; // デフォルトの解像度

      // --- シーンの準備ができたときにローダーを非表示にする ---
      sceneEl.addEventListener('loaded', () => {
        console.log('[a-scene] loaded');
        loaderEl.style.display = 'none';
      });

      // --- カメラ解像度の取得 ---
      sceneEl.addEventListener('camera-init', (data) => {
        console.log('[camera-init]', data);
        if (data.detail.error) {
            toastEl.classList.add('show');
            setTimeout(() => toastEl.classList.remove('show'), 3000);
            return;
        }
        const video = document.querySelector('video');
        if (video) {
          video.addEventListener('loadedmetadata', () => {
            // 実際のビデオストリームから解像度を記憶しておく
            captureWidth = video.videoWidth;
            captureHeight = video.videoHeight;
            console.log(`[camera] Capture resolution discovered: ${captureWidth}x${captureHeight}`);
          });
        }
      });

      markerEl.addEventListener('markerFound', () => {
        console.log('[marker] found');
      });

      markerEl.addEventListener('markerLost', () => {
        console.log('[marker] lost');
      });

      // --- モデル読み込みログ ---
      modelEl.addEventListener('model-error', (e) => {
        console.error('[model] Error loading model:', e.detail.src);
        alert(`Failed to load model from ${e.detail.src}. Check console for details.`);
      });

      // --- 撮影ボタンの処理 ---
      captureBtn.addEventListener('click', () => {
        // 1. 撮影直前に、記憶しておいた解像度をscreenshotコンポーネントに設定
        sceneEl.setAttribute('screenshot', {
          width: captureWidth,
          height: captureHeight
        });

        // 2. A-Frameが設定を適用するのを待つため、一瞬遅延させる
        setTimeout(() => {
          const video = document.querySelector('video');
          const glCanvas = sceneEl.components.screenshot.getCanvas('perspective');

          if (!video || !glCanvas || glCanvas.width === 0) {
            console.error('Failed to get valid canvas for capture.');
            return;
          }

          const compositeCanvas = document.createElement('canvas');
          const ctx = compositeCanvas.getContext('2d');

          compositeCanvas.width = captureWidth;
          compositeCanvas.height = captureHeight;

          // 背景(ビデオ)と前景(3Dモデル)を合成
          ctx.drawImage(video, 0, 0, captureWidth, captureHeight);
          ctx.drawImage(glCanvas, 0, 0);

          // 画像としてダウンロード
          const link = document.createElement('a');
          link.href = compositeCanvas.toDataURL('image/png');
          link.download = 'ar-capture.png';
          link.click();
        }, 0); // 0msの遅延で、次の描画サイクルで処理を実行させる
      });
    });
  </script>
</body>
</html>
